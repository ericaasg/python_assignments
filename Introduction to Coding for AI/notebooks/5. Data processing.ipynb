{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68492be",
   "metadata": {},
   "source": [
    "# Introduction to Coding for AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f1b63",
   "metadata": {},
   "source": [
    "## 5. Data processing\n",
    "\n",
    "So far we have been working with very small data snippets, but of course, datasets are normally stored in files or databases. In our challenge, we‚Äôll focus on tabular data, which is a very common and flexible format that allows you to process text and numerical values. Think of the data you normally find in spreadsheets.\n",
    "\n",
    "Let‚Äôs take a look at some of the common data formats for handling tabular data in real-world situations: TXT, CSV, and JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d0a11",
   "metadata": {},
   "source": [
    "### 5.1. Directory tree\n",
    "\n",
    "All the data in your computer has a directory tree structure. For example, you can see the content of our challenge directory in your file explorer:\n",
    "\n",
    "<img src=\"../data/content/directory_tree.png\" width=\"90%\"/>\n",
    "\n",
    "And then think of the directory tree representing these files as the following one:\n",
    "\n",
    "```\n",
    "Introduction to Coding for AI/\n",
    "‚îÇ\n",
    "‚îú‚îÄ data/\n",
    "‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îú‚îÄ content/\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ image_1.png\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ image_2.png\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ image_3.png\n",
    "‚îÇ  ‚îÇ  ‚îú‚îÄ ...\n",
    "‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îú‚îÄ datasets/\n",
    "‚îÇ     ‚îú‚îÄ dataset_1.csv\n",
    "‚îÇ     ‚îú‚îÄ dataset_2.json\n",
    "‚îÇ     ‚îú‚îÄ dataset_3.xlxs\n",
    "‚îÇ     ‚îú‚îÄ ...\n",
    "‚îÇ   \n",
    "‚îú‚îÄ notebooks/\n",
    "   ‚îú‚îÄ notebook_1.ipynb\n",
    "   ‚îú‚îÄ notebook_2.ipynb\n",
    "   ‚îú‚îÄ notebook_3.ipynb\n",
    "   ‚îú‚îÄ ...\n",
    "```\n",
    "\n",
    "The first step to load data from your computer is to tell Python where to search for it. Here we will import a module called `glob` from the standard library also called `glob`. *glob* reads all the files inside the **folder** (also called **directory**) that you specify and returns a list with their paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abe994e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_file_paths_here:\n",
      "['./3. Data structures and handling errors.ipynb', './library.py', './5. Data processing.ipynb', './__pycache__', './2. Flow and Functions.ipynb', './4. Custom classes and modules.ipynb', './1. Getting Started.ipynb', './6. Training and evaluating models.ipynb']\n",
      "\n",
      "python_file_paths_here:\n",
      "['./library.py']\n",
      "\n",
      "all_file_paths_above:\n",
      "['../dist', '../README.md', '../local', '../data', '../notebooks']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "all_file_paths_here = glob(\"./*\")\n",
    "python_file_paths_here = glob(\"./*.py\")\n",
    "all_file_paths_above = glob(\"../*\")\n",
    "\n",
    "print(f\"all_file_paths_here:\\n{all_file_paths_here}\\n\")\n",
    "print(f\"python_file_paths_here:\\n{python_file_paths_here}\\n\")\n",
    "print(f\"all_file_paths_above:\\n{all_file_paths_above}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9ae29",
   "metadata": {},
   "source": [
    "The string we passed to `glob` starts with one dot and a forward slash (`./`). The dot (`.`) means **here**, the current directory where this Jupyter Notebook is located in your directory tree, and the forward slash (`/`) indicates that there is a directory there. Similarly, you use two dots (`../`) to tell Python that it should go one directory level **above**, and from there start following the rest of the path. You can repeat these two dots as many times as you want to go up in your directory tree, so `../../../` would go up three levels for example.\n",
    "\n",
    "Next we see a star (`*`) and a star followed by the file extension of python files (`.py`). The star alone (`*`) means **everything**, so it tells `glob` to add all files and folders to the list that it will return. However, when the star is written next to other characters, its meaning changes. So, (`*.py`) indicates to `glob` to add all files ending with `.py` to the list that it will return.\n",
    "\n",
    "To recap, to open files located in the same directory as the notebook, use one dot only, so `./file.text` searches for `file.text` in the current directory, and `./folder/file.text` searches for `file.text` in a folder called `folder` located in the same place as the jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd544d",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "1. Copy the code of the cell above into the cell below.\n",
    "2. Add a command that gets the list of all jupyter notebook files (`.ipynb`) in the current directory.\n",
    "3. Store this list in a variable with a suitable name and print them.\n",
    "4. Run the cell to show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1efaa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61902717",
   "metadata": {},
   "source": [
    "### 5.2. Text Data\n",
    "\n",
    "In the following sections, we'll see how to **read** data from files, **transform** it to be ready for analysis, and **write** it back to your hard drive. Let's begin with an example of text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6911a",
   "metadata": {},
   "source": [
    "#### 5.2.1. Read\n",
    "\n",
    "In the file that contains the notebooks, there is also a directory with datasets. We‚Äôll start with a dataset called `spam.txt` that contains a collection of SMS messages. This dataset is a simplified version of the original SMS Spam Collection Dataset found in [Kaggle](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset).\n",
    "In the dataset, each line contains the SMS text as well as the category (class) spam or ham. In case you don't know it, ham means that the SMS is ok and not spam.\n",
    "Emails already have a spam filter, but wouldn't it be great if phone companies could do the same? That's what we'll try to help them with.\n",
    "Let's start by reading the data, below is the method to read text files line-by-line, check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d338a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat.... The class of this SMS is: ham\n",
      "\n",
      "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat.... The class of this SMS is: ham\\n'\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/datasets/spam.txt\", \"r\") as file_handle:\n",
    "    first_line = file_handle.readline()\n",
    "    print(first_line)  # String formatted by print()\n",
    "    print(repr(first_line))  # Raw, printable representation of the string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5597323",
   "metadata": {},
   "source": [
    "Let‚Äôs unpack this code through the steps‚Äô description below:\n",
    "\n",
    "**with ... as ...**\n",
    "\n",
    "The statement `with <object> as <handle>:` means that the code that you place after `with` has to return an object, and that you will assign this object to the variable indicated in `<handle>`. In our case, the built-in function `open()` returns an object associated with the file you are opening. When Python opens a file, it must close it once it has finished working with it, otherwise, the file could become corrupted. One way of doing this is by calling the method `<object.close()>`, but to simplify our code, when we use the `with ... :` method it creates a code block in the next line after the colon. Once your program finishes working inside this code block and goes out again, the `with` automatically closes the file for you. \n",
    "\n",
    "**open( )**\n",
    "\n",
    "The statement `open(\"<path/to/filename.extension>\", \"mode\")` opens a file with the **mode** that you indicate. The modes that we are interested in are `r`, `w` and `a`.\n",
    "  - `r`: Only reads the file. This is a safe option to avoid messing up  the data.\n",
    "  - `w`: Creates a file to write. Be careful, if the file exists already it will delete its content first. Better avoid this, unless you are sure of it!\n",
    "  - `a`: Opens a file to write, but instead of overwritting its content, everything you write is appended at the end of the file.\n",
    "\n",
    "**.readline( )**\n",
    "\n",
    "Next we see that `first_line = file_handle.readline()` reads one line from the `file_handle` and stores it in the variable `print_line`. In the example, we only execute `.readline()` one time, so we only read the first line in the file. What if you want to read multiple lines? In that case, you can execute it inside a `for` loop (we‚Äôll see the syntax in the following example). There is also a method called `.readlines()`, the plural, that reads all the lines in the file, but it‚Äôs not advised when you work with very large files! It‚Äôs good for you to know this method exists, but to stay away from trouble, let‚Äôs only use the first method and always read one line at a time. slow and steady wins the race üòâ\n",
    "\n",
    "**repr( )**\n",
    "\n",
    "Even if the `print()` function doesn't show it, there is a \"\\n\" at the end of each line in texts.\n",
    "In the example, we use the function `repr()` to show it.\n",
    "We'll explain a bit what is `repr()` now, but the main point for you to remember, is that at the end of each line of text in a file, there is a *hidden* character `\\n`.\n",
    "\n",
    "Notice how the first print command (`print(first_line)`) formats the string in `print_line`, so instead of showing `\\n` at the end of the line, it **adds** a new line. Conversely, the second print command (`print(repr(first_line))`) uses `repr()` to get the *printable representation* of the string. This means that instead of interpreting the escape characters inside strings, `print()` will show all charachters inside the string, or it *raw* content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7fed63",
   "metadata": {},
   "source": [
    "#### 5.2.2. Transform\n",
    "\n",
    "Now let's start doing some processing of the text in this file. As an exercise, let's create a list with the SMS texts and a list with the corresponding *classes* (*ham* or *spam*). **Attention:** in the context of *Python programming language*, a *class* is a code structure. In the context of *Machine Learning*, a *class* is the category of something. In the latter case, the SMS text may belong to the class *ham* or to the class *spam*.\n",
    "\n",
    "**String parsing**\n",
    "\n",
    "The first step is to know how to process, or **parse**, each line of text. In the previous cell we saw the first line in the file, so assuming all lines have the same structure, we can create a program that:\n",
    "\n",
    "1. Splits the SMS text from the SMS class using the string `\". The class of this SMS is: \"` as a separator.\n",
    "2. The SMS text is ready, so now we just need to remove the `\\n` trailing the class name `ham`.\n",
    "3. Then store the SMS in one list and its class in another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02144732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of instances: 5573\n",
      "First SMS:\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "First class:\n",
      "'ham'\n"
     ]
    }
   ],
   "source": [
    "# Important:\n",
    "# Declare the lists before you use them,\n",
    "# otherwise you'll get an error:\n",
    "sms_texts = []\n",
    "sms_classes = []\n",
    "\n",
    "with open(\"../data/datasets/spam.txt\", \"r\") as file_handle:\n",
    "    \n",
    "    counter = 0\n",
    "    for line in file_handle:\n",
    "        \n",
    "        sms_text, sms_class = line.split(\". The class of this SMS is: \")\n",
    "        \n",
    "        sms_class = sms_class[:-1]  # Remove \"\\n\"\n",
    "        \n",
    "        sms_texts.append(sms_text)\n",
    "        sms_classes.append(sms_class)\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(f\"Total number of instances: {counter}\")\n",
    "print(f\"First SMS:\\n{sms_texts[0]}\")\n",
    "print(f\"First class:\\n{repr(sms_classes[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace865b1",
   "metadata": {},
   "source": [
    "All the elements in the program above are already known to us. Let's go briefly over them to make sure everything is clear.\n",
    "\n",
    "- First we initialize our data structures, which are the two lists where we'll store our clean data after processing it. We must always initialize data structures before modifying them, otherwise, Python will produce an error.\n",
    "- Then we open the file and start reading its text, line by line. The variable `file_handle` is an **iterator**, so when we place it in a `for` loop it returns item after item until no more elements are left.\n",
    "- Next, we split each text line with a string **pattern**. In our case, we know that the same text is always repeated between each SMS and its class: `\". The class of this SMS is: \"`, including a space at the end of the string. \n",
    "- Afterwards, we remove the last character `\\n` from the string `ham\\n` and store the *cleaned* string `ham` back in the variable `sms_class`. For this we *slice* the string; remember when we saw *slicing*? We use the command `sms_class[:-1]`, which is the same as `sms_class[0:-1]`, so the start index is `0` and the end index is `-1`. In other words, we keep all the characters in the string, from index `0` and up to, *but not including*, the last index to remove the last character `\\n`.\n",
    "- Finally, we append the string `sms_text` in the list `sms_texts`, and the string `sms_class` in the list `sms_classes`.\n",
    "- Notice that before the `for` loop, we initialize a `counter` and then increase its value by `1` after each `for` loop. In this way, we can count how many lines are in our text file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae44ae",
   "metadata": {},
   "source": [
    "for index, line in enumerate(file_handle):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69197f0b",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "1. Copy the code of the cell above into the cell below.\n",
    "2. Replace the two lists `sms_texts` and `sms_classes` with four new lists:\n",
    "  - A list for storing the text of ham messages.\n",
    "  - A list for storing the text of spam messages.\n",
    "  - A list for storing the class of ham messages.\n",
    "  - A list for storing the class of spam messages.\n",
    "3. Count how many *ham* and how many *spam* elements are in the dataset and print the answers.\n",
    "4. Run the cell to show the results.\n",
    "\n",
    "- **Going further**: Instead of having four separate lists, create a dictionary with four keys. Each key should be a string with the name of the variable, its corresponding value should be the list with data. For example, `sms_texts = []` and `sms_classes = []` would become `data_dictionary = {\"sms_texts\": [], \"sms_classes\": []}`. Therefore, `sms_texts.append(sms_text)` would become `data_dictionary[\"sms_texts\"].append(sms_text)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01c297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f697180a",
   "metadata": {},
   "source": [
    "#### 5.2.3. Write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b24fa5",
   "metadata": {},
   "source": [
    "The last step of our text data processing is to save the data.\n",
    "Below you can see that we repeat the same processing we did before, and afterward we create two new files to save the SMS texts and the SMS classes separately.\n",
    "\n",
    "Also, notice that when we write each line, we append a new line character `\\n` at the very end, so that the next line we write starts in a new line below. There are two ways for adding `\\n` at the end of the SMS text, by inserting into the SMS text or by appending it at the end of the SMS text.\n",
    "To insert it, we can use the formatting method that we have used before: `f\"{sms_text}\\n\"`, and to append it we can use the `+` sign as it concatenates the two strings on its left and right sides: `sms_text + \"\\n\"`.\n",
    "Both methods produce the same result, so we use the `+` method as in this case is the simplest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04584608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data:\n",
    "sms_texts = []\n",
    "sms_classes = []\n",
    "with open(\"../data/datasets/spam.txt\", \"r\") as file_handle:\n",
    "    for line in file_handle:\n",
    "        sms_text, sms_class = line.split(\". The class of this SMS is: \")\n",
    "        sms_class = sms_class[:-1]\n",
    "        sms_texts.append(sms_text)\n",
    "        sms_classes.append(sms_class)\n",
    "\n",
    "# Save data:\n",
    "filename = \"../data/datasets/sms_texts.txt\"\n",
    "data_list = sms_texts\n",
    "with open(filename, \"w\") as file_handle:\n",
    "    for item in data_list:\n",
    "        line = item + \"\\n\"\n",
    "        file_handle.write(line)\n",
    "\n",
    "# Save data:\n",
    "filename = \"../data/datasets/spam_classes.txt\"\n",
    "data_list = sms_classes\n",
    "with open(filename, \"w\") as file_handle:\n",
    "    for item in data_list:\n",
    "        line = item + \"\\n\"\n",
    "        file_handle.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4708ea9",
   "metadata": {},
   "source": [
    "You can also see that instead of typing the file path inside the `open()` function, we define it as a variable above it. Also, instead of using a different variable name for the list inside the `for` loop, we pass it the same variable name `data_list`.\n",
    "This optimization of code to make it more reusable is called code **refactoring**, and replacing values inside pieces of code with variables is called **extracting** parameters.\n",
    "More concretely, we can reuse the code for writing a file if we specify the `filename` and the `data_list`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a06754",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "1. Copy the code of the cell above into the cell below.\n",
    "2. Below the code, create a *function* with the arguments `filename` and `data_list`.\n",
    "3. Below the function definition, call the function two times. The first time, provide it with the parameters to save the SMS texts, and the second time, provide it with the parameters to save the SMS classes. For example, if you name the function save_data(), you should call it as follows: `save_data(filename, data_list)`.\n",
    "4. Run the cell to execute the code.\n",
    "\n",
    "- **Going further**: If you feel more adventurous, create a class called `DataCenter`. The class should have two methods:\n",
    "  1. `preprocess_sms()` reusing the code we wrote for processing our SMS data. It should take as parameters the `filename` to open, and the `cut_pattern` used to split the *text* from the *class*. Finally, it should return two lists: `sms_texts` and `sms_classes`.\n",
    "  2. `save_data()` reusing the code we wrote for saving text data.\n",
    "\n",
    "Then create an instance of the class, call one time the `preprocess_sms()` method, and call two times the `save_data()` method to save the SMS texts and the SMS classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3651e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72f8c8d8",
   "metadata": {},
   "source": [
    "### 5.3. CSV Data\n",
    "\n",
    "Reading and writing took lots of steps in the code we used above. Considering that all these steps are repeated often, it would be a good idea to standardize the read-and-write procedures in a single module. What about standardizing also the *cut pattern* that we use to separate the different features in our data? This is where Comma-Separated Values or **CSV** files come in handy. Furthermore, to simplify the read-and-write procedures, we'll use **Pandas**, an external library that specializes in tabular data. Normally, you have to install external libraries manually, but in our case, Anaconda comes with all the Data Science libraries we need, including Pandas.\n",
    "\n",
    "Reading and writing took lots of steps in the code we used above. However, all these steps are repeated often, so it would be a good idea to standardize the read-and-write procedures in a reusable function. But what about the cut pattern we use to separate different features in our data? Fret not, we can standardize these too, and that's where Comma-Separated Values (CSV) files come in handy. \n",
    "\n",
    "Yes, but isn't this going to be complicated? No, it doesn't have to be, because we'll use Pandas üêº, an external library that specializes in tabular data. While you normally would have to install external libraries manually, Anaconda is prepared to provide you with all the Data Science libraries we need. \n",
    "\n",
    "So, let's get into coding and import this useful Pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eba8c2",
   "metadata": {},
   "source": [
    "#### 5.3.1 Read\n",
    "\n",
    "Let's go straight to an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857be523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms class\n",
       "0  Go until jurong point, crazy.. Available only ...   ham\n",
       "1                      Ok lar... Joking wif u oni...   ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3  U dun say so early hor... U c already then say...   ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../data/datasets/spam.csv\")\n",
    "\n",
    "print(f\"Type of data: {type(data)}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a191bd80",
   "metadata": {},
   "source": [
    "Done! Great isn't it! üòä\n",
    "\n",
    "When we write `import pandas as pd`, the `pd` is just a way to assign a shorter name to the module. This helps to make the code look cleaner and saves time when writing lots of code. For example, when calling the method to read CSV files, now we can write `pd.read_csv()` instead of the longer `pandas.read_csv()`.\n",
    "\n",
    "Finally, when you call the method `.head()` of the object `data`, it displays the top five rows of your data with a pretty-looking table that makes it easier to inspect the data. By the way, the data type of the object returned by `pd.read_csv()` is called `DataFrame`. You can inspect it with the function `type()` as before:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2113bb48",
   "metadata": {},
   "source": [
    "#### 5.3.2 Transform\n",
    "\n",
    "Below you can see how `spam.txt` changes from `spam.csv`, the CSV version of our dataset. We'll print two lines of the CSV file as the first line has the name of each feature (`sms` and `class`). In the second line you can see that the cut pattern `. The class of this SMS is: ` is gone. This pattern is no longer needed, as it has been replaced by other markers, such as placing the features (texts and classes) between double quotes (`\" \"`), and by separating each feature with a comma (hence the name CSV). This means that we no longer need to transform our data, this is already done when we use CSV conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e1376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat.... The class of this SMS is: ham\\n' \n",
      "\n",
      "'\"sms\",\"class\"\\n'\n",
      "'\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\",\"ham\"\\n'\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/datasets/spam.txt\", \"r\") as file_handle:\n",
    "    line = repr(file_handle.readline())\n",
    "    print(line, \"\\n\")\n",
    "\n",
    "with open(\"../data/datasets/spam.csv\", \"r\") as file_handle:\n",
    "    line = repr(file_handle.readline())\n",
    "    print(line)\n",
    "    line = repr(file_handle.readline())\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5c29b",
   "metadata": {},
   "source": [
    "#### 5.3.3 Write\n",
    "\n",
    "Finally, we can also save our features (texts and classes) as individual files. For this, we select the respective column in our dataframe and use Pandas to save it.\n",
    "\n",
    "#### Note:\n",
    "We are importing pandas again and reading the data again, even though we already did this in the previous cell and the data is already in memory. We did the same when we defined our custom functions and we‚Äôll keep repeating these loads and definitions. Why? Simply to make the cells in the notebook stand-alone, so you can run them independently and without having to run all the cells above first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f97ad596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../data/datasets/spam.csv\")\n",
    "\n",
    "data.to_csv(\"../data/datasets/sms_texts.csv\", columns=[\"sms\"], index=False)\n",
    "data.to_csv(\"../data/datasets/sms_classes.csv\", columns=[\"class\"], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5183a4f0",
   "metadata": {},
   "source": [
    "Two lines of code, amazing. The `.to_csv()` can take additional parameters, like `columns` to indicate a list with the names of the columns that you want to save, or `index` to indicate if you want to add index numbers in your CSV file or not. How can we know all the parameters that are possible to pass to this method? The best way to understand a library is through its documentation. It may look a bit complex, but after a few minutes, you will become comfortable reading it.\n",
    "\n",
    "For example, [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) you can find the documentation for `.to_csv()`. At the top, you can see the definition of the method, and the default value for its arguments. Below you will find a detailed description of each parameter and at the bottom some example exercises.\n",
    "\n",
    "Part of being a software developer is reading the libraries' documentation and searching for answers in technical forums. Ask any software developer engineer, and they will tell you they do this on a daily basis! It takes a bit of time to get used to these kinds of documents and navigate them confidently, but once you come to grips with their common structure, it becomes much easier and more enjoyable. Seriously, it's a promise üòâ\n",
    "\n",
    "So let's get some practice and do the exercise below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d795c3",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "1. Google \"pandas read excel\" and \"pandas write dataframe to excel\", and find the pages in the official Pandas documentation that describe these two methods.\n",
    "    - **Tip:** The main page of the Pandas' official documentation is https://pandas.pydata.org/pandas-docs/stable/reference/\n",
    "2. At the top of the documentation pages, you can find the **signature** of the methods. The signature shows you the parameters that you can pass to the methods. Read the arguments that each function has, and notice the default values of each.\n",
    "3. At the top of the documentation pages you can find examples of how to use the methods.\n",
    "3. In the cell below, load the file `\"../data/datasets/spam.xlsx\"` and\n",
    "    - save the column `\"sms\"` in a file called `\"../data/datasets/sms_texts.xlsx\"`\n",
    "    - save the column `\"class\"` in a file called `\"../data/datasets/sms_classes.xlsx\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb251c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f7e9632",
   "metadata": {},
   "source": [
    "### 5.4. JSON Data\n",
    "\n",
    "Finally, we'll see another popular format used to transfer data between processes, databases, and to communicate between different programming languages: JSON (JavaScript Object Notation).\n",
    "More concretely, JSON is a standard file and data-interchange format that uses human-readable text to store and transmit data objects consisting of **attribute‚Äìvalue pairs** (like **key-value pairs** in Python dictionaries) and **arrays** (like **lists** in Python).\n",
    "The good news is that the JSON format is very similar to Python dictionaries, so you are already familiar with its structure.\n",
    "When a JSON only has one item, Python converts it into a dictionary, and when it has multiple items, Python converts it into a list of dictionaries. These are examples of JSON objects:\n",
    "\n",
    "```\n",
    "single_user = {\n",
    "    \"name\": \"John\",\n",
    "    \"last_name\": \"Smith\",\n",
    "    \"age\": 24,\n",
    "    \"hobby\": {\n",
    "        \"reading\" : true,\n",
    "        \"gaming\" : false,\n",
    "        \"sport\" : \"football\"\n",
    "    },\n",
    "    \"children\" : [\"Peter\", \"Laura\"]\n",
    "}\n",
    "\n",
    "multiple users = [\n",
    "    {\"name\": \"John\", ...},\n",
    "    {\"name\": \"Jessica\", ...},\n",
    "    {\"name\": \"Peter\", ...}\n",
    "]\n",
    "```\n",
    "\n",
    "Let's go over some subtle differences between JSON and Python:\n",
    "- Wwhat in Python is a dictionary (`dict`), in JSON is called an `Object`.\n",
    "- A `list` in Python is called an `Array` in JSON.\n",
    "- The value `None` in Python is called `null` in JSON.\n",
    "- `True` and `False` have the first letter capitalized, but in JSON they are all lowercase.\n",
    "\n",
    "| Python |  JSON  |\n",
    "|:------:|:------:|\n",
    "|  dict  | Object |\n",
    "|  list  |  Array |\n",
    "|  True  |  true  |\n",
    "|  False |  false |\n",
    "|  None  |  null  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261136cf",
   "metadata": {},
   "source": [
    "#### 5.4.1 Read\n",
    "\n",
    "\n",
    "To load JSON data into a Python dictionary (or a list when there are multiple key-value pairs), you need to import the module `json`.\n",
    "You can use this module to read a file or to decode information in a text string.\n",
    "To start, let's read the same dataset we used in the CSV example (the SMS ham/spam one üòâ), but in JSON format.\n",
    "For this, you can use the method `.load()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0e26870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of data is: \n",
      " <class 'list'>\n",
      "The number of elements in the data is: \n",
      " 5573\n",
      "The first element in the data is: \n",
      " {'sms': 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'class': 'ham'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read a FILE:\n",
    "with open(\"../data/datasets/spam.json\", \"r\") as file_handle:\n",
    "    data = json.load(file_handle)\n",
    "    print(f\"The type of data is: \\n {type(data)}\")\n",
    "    print(f\"The number of elements in the data is: \\n {len(data)}\")\n",
    "    print(f\"The first element in the data is: \\n {data[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4919a55",
   "metadata": {},
   "source": [
    "Wow, the results for the first element in the data looks crammed and not an easy read!. But as you should know by now, in programming languages, there‚Äôs always a solution üòâ. If you would like to improve the way dictionaries are printed, you can import the module `PrettyPrinter` from the library `pprint`. Once you import this module: \n",
    "- Create an instance of it in the same way you created instances of classes before. For example, `pp = PrettyPrinter()` creates an instance called `pp`.\n",
    "- Then, use the instance object to call the method `pprint()`. For example, you can execute `pp.pprint(dictionary)` to print more *prettily* the contents of the dictionary.\n",
    "\n",
    "Take a look at the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d98042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element in the data is:\n",
      "{'class': 'ham',\n",
      " 'sms': 'Go until jurong point, crazy.. Available only in bugis n great world '\n",
      "        'la e buffet... Cine there got amore wat...'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "# Read a FILE:\n",
    "with open(\"../data/datasets/spam.json\", \"r\") as file_handle:\n",
    "    data = json.load(file_handle)\n",
    "    print(\"The first element in the data is:\")\n",
    "    pp.pprint(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60135f8",
   "metadata": {},
   "source": [
    "Much better, isn‚Äôt it? You can now instantly see the `class` in the first line, and separately the `sms` text on the second. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2379615",
   "metadata": {},
   "source": [
    "#### 5.4.2 Transform\n",
    "\n",
    "Great, the data is in a dictionary and you can read it, so why don‚Äôt we look at how to process it. For example, let‚Äôs add a feature called `binary_class` with the value `0` when the text is `spam`, and with the value `1` when the text is `ham`. For this, we can iterate over our list of dictionaries with a *for* loop, or use pandas. \n",
    "\n",
    "Frequently, data has missing values, so it could be the case that some texts have no `class` value.\n",
    "It is important to catch these cases and decide what to do with them, otherwise, your program could crash when trying to add a number with a `None` for example. \n",
    "There are multiple alternatives to solve this issue. You could remove the rows that have any missing value (although you may end up with no data!), or you could replace them with educated guesses, for example with the average value in the column, or the average between the two adjacent rows. This process of filling in missing values is called **imputation**.\n",
    "Observe in both of the methods below the alternative ways to verify that your data is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db44c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of \"data\" is:\n",
      "  <class 'list'>\n",
      "The type of each item in \"data\" is:\n",
      "  <class 'dict'>\n",
      "\n",
      "The first element in the ORIGINAL data is:\n",
      "{'class': 'ham',\n",
      " 'sms': 'Go until jurong point, crazy.. Available only in bugis n great world '\n",
      "        'la e buffet... Cine there got amore wat...'}\n",
      "\n",
      "The first element in the TRANSFORMED data is:\n",
      "{'binary_class': 1,\n",
      " 'class': 'ham',\n",
      " 'sms': 'Go until jurong point, crazy.. Available only in bugis n great world '\n",
      "        'la e buffet... Cine there got amore wat...'}\n"
     ]
    }
   ],
   "source": [
    "# Iterating over a list of dictionaries with a for loop\n",
    "\n",
    "import json\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter()\n",
    "\n",
    "\n",
    "# LOAD the data:\n",
    "with open(\"../data/datasets/spam.json\", \"r\") as file_handle:\n",
    "    data = json.load(file_handle)\n",
    "\n",
    "# INSPECT the data:\n",
    "print(f'The type of \"data\" is:\\n  {type(data)}')\n",
    "print(f'The type of each item in \"data\" is:\\n  {type(data[0])}')\n",
    "print(\"\\nThe first element in the ORIGINAL data is:\")\n",
    "pp.pprint(data[0])\n",
    "\n",
    "# TRANSFORM the data:\n",
    "for index, item in enumerate(data):\n",
    "    if item[\"class\"] == \"spam\":\n",
    "        data[index][\"binary_class\"] = 0\n",
    "    elif item[\"class\"] == \"ham\":\n",
    "        data[index][\"binary_class\"] = 1\n",
    "    else:\n",
    "        # Warn if there are missing values:\n",
    "        print(f'The class must be \"spam\" or \"ham\". The class of item {index} is: {item[\"class\"]}')\n",
    "\n",
    "# VERIFY the data:\n",
    "print(\"\\nThe first element in the TRANSFORMED data is:\")\n",
    "pp.pprint(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d436b",
   "metadata": {},
   "source": [
    "When we create our new `binary_class` feature, we don't want to modify the temporary variable returned in the `for` loop, but we want to modify the original data object.\n",
    "To do this, we use the function `enumerate()` that we introduced in notebook '2. Flow and Functions*.\n",
    "This function helps us because it returns the `index` and the `item` of the list in each iteration, so we evaluate our logical conditions on the `item`, and then we modify the corresponding item in `data` by pointing to it with its `index`.\n",
    "Notice that you can use consecutive pairs of brackets `[]` to go deeper in the data structure. For example:\n",
    "- `data` returns a list.\n",
    "- `data[index]` returns a dictionary.\n",
    "- `data[index][\"binary_class\"]` returns a number.\n",
    "\n",
    "Now let's see how to perform the same procedure in a simplified way by using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ac3e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 sms class\n",
      "0  Go until jurong point, crazy.. Available only ...   ham\n",
      "1                      Ok lar... Joking wif u oni...   ham\n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
      "3  U dun say so early hor... U c already then say...   ham\n",
      "4  Nah I don't think he goes to usf, he lives aro...   ham \n",
      "\n",
      "                                                 sms class  binary_class\n",
      "0  Go until jurong point, crazy.. Available only ...   ham             1\n",
      "1                      Ok lar... Joking wif u oni...   ham             1\n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam             0\n",
      "3  U dun say so early hor... U c already then say...   ham             1\n",
      "4  Nah I don't think he goes to usf, he lives aro...   ham             1 \n",
      "\n",
      "Number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Applying a function to a Pandas data frame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# LOAD the data:\n",
    "data = pd.read_json(\"../data/datasets/spam.json\")\n",
    "\n",
    "# INSPECT the data:\n",
    "print(data.head(), \"\\n\")\n",
    "\n",
    "# TRANSFORM the data:\n",
    "data[\"binary_class\"] = data.apply(\n",
    "    lambda row: 0 if row[\"class\"] == \"spam\" else 1,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# VERIFY the data:\n",
    "print(data.head(), \"\\n\")\n",
    "\n",
    "# Warn if there are missing values:\n",
    "nan_values = data[\"binary_class\"].isnull().sum()\n",
    "print(f\"Number of missing values: {nan_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a717e",
   "metadata": {},
   "source": [
    "Let‚Äôs unpack what we‚Äôve done. Here we use the method `.read_json()` to load the JSON data directly into a Pandas data frame named `data`.\n",
    "Afterward, in `# TRANSFORM the data` we create a new column with the same notation used to create a new *key-value* pair in a dictionary: `dictionary[\"new_key\"] = new_value` or `pandas_dataframe[\"new_column\"] = new_series_of_values`.\n",
    "\n",
    "To create the new series of values that will be assigned to our new column `binary_class`, we use the method `.apply()` on `data`.\n",
    "This method applies a **function** iteratively over the **columns** or the **rows** of a Pandas data frame.\n",
    "\n",
    "In the first parameter, we pass the function to `.apply()` with a syntax called **lambda function**.\n",
    "Lambda functions are the same as regular functions, but have a shortened syntax that makes our code shorter and easier to read.\n",
    "The syntax of *lambda* functions is: `lambda input: computation`. Notice that you start with the keyword `lambda` to define the function, and the result you get for each row is the value returned by the `computation`.\n",
    "In our case, the computation is `0 if row[\"class\"] == \"spam\" else 1`, so our lambda function returns `0` when the row `class` is `spam`, and returns `1` when the row `class` is `ham`.\n",
    "\n",
    "In the second parameter passed to `.apply()`, we indicate that we want to iterate over rows.\n",
    "`.apply()` iterates over columns when its parameter `axis=0`, and iterates over rows when its parameter `axis=1`.\n",
    "As we want to check the value of `class` in each row, we set `axis=1`.\n",
    "\n",
    "And there you go, you now know how to process data with JSON, and scan any dataset for missing values. üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1fdb04",
   "metadata": {},
   "source": [
    "#### 5.4.3 Write\n",
    "\n",
    "Finally, we are ready with our new data, the next step is to save it back as a JSON. These are the methods for storing dictionaries and Pandas data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6c195a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a dictionary as a JSON\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"../data/datasets/spam.json\", \"r\") as file_handle:\n",
    "    data = json.load(file_handle)\n",
    "\n",
    "for index, item in enumerate(data):\n",
    "    if item[\"class\"] == \"spam\":\n",
    "        data[index][\"binary_class\"] = 0\n",
    "    elif item[\"class\"] == \"ham\":\n",
    "        \n",
    "        data[index][\"binary_class\"] = 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# SAVE the data:\n",
    "with open(\"../data/datasets/spam_dictionary.json\", \"w\") as file_handle:\n",
    "    json.dump(data, file_handle, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162617f",
   "metadata": {},
   "source": [
    "To have more clarity in this example code about saving data, we skip the step of checking for missing values, but you should always perform it Flow control elements (for, if, else, etc.) can‚Äôt be left empty, they always must have an instruction. Therefore, we write `pass` to tell Python that we don‚Äôt want to do anything and simply continue to the next step in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a008665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a Pandas data frame as a JSON\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_json(\"../data/datasets/spam.json\")\n",
    "\n",
    "data[\"binary_class\"] = data.apply(\n",
    "    lambda row: 0 if row[\"class\"] == \"spam\" else 1,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# SAVE the data:\n",
    "data.to_json(\"../data/datasets/spam_dataframe.json\", indent=2, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811797c8",
   "metadata": {},
   "source": [
    "The last line shows the method to save a Pandas data frame as a JSON, and it has two additional parameters.\n",
    "`indent=2` adds two indentation spaces to make the JSON file easier to read, and `orient=\"records\"` tells Pandas to store it with the common pattern for data records.\n",
    "\n",
    "JSON is a universal translator between programming languages and you'll encounter it often when receiving and sending data. Now you are ready to start communicating with databases around the world! üòé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbd780",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "1. Open the JSON file in a simple text editor. Don't use Excel, but instead use the default text editors **textEdit** in Mac, or **Notepad** in Windows.\n",
    "2. Open the [official documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html) for `.to_json()` and find the alternative values that you can pass to the parameter `orient`.\n",
    "3. Copy the code of the cell above into the cell below.\n",
    "4. Save the data with all the different `orient` values (one line of code per value) and compare the output format in your text editor.\n",
    "4. Run the cell to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454644a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
